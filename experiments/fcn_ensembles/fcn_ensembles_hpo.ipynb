{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-01T18:57:35.409422654Z",
     "start_time": "2024-02-01T18:57:31.677974316Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "import copy\n",
    "import itertools\n",
    "import os\n",
    "import time\n",
    "from typing import (\n",
    "    Dict,\n",
    "    Final,\n",
    "    List,\n",
    "    Union,\n",
    ")\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import yaml\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "import probabilisticml as pml\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "ENSEMBLE_SIZE: Final = 12\n",
    "MAX_EPOCHS: Final = 5000\n",
    "WEIGHT_DECAY: Final = [0.01, 0.001, 0.0001]\n",
    "BATCH_SIZE: Final = [32, 64]\n",
    "VAL_SIZE: Final = [0., 0.1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-01T18:57:36.369727413Z",
     "start_time": "2024-02-01T18:57:36.330813766Z"
    }
   },
   "id": "3ec6edec7a215789"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def load_config(config_path: str) -> tuple[dict, list]:\n",
    "    \"\"\"Load the configuration file.\"\"\"\n",
    "    with open(config_path, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return config\n",
    "\n",
    "\n",
    "def save_config(config, path):\n",
    "    \"\"\"Save the configuration file.\"\"\"\n",
    "    with open(path, 'w') as file:\n",
    "        yaml.dump(config, file)\n",
    "\n",
    "\n",
    "def load_data(dataset: str, seed: int, val_size: float) -> tuple:\n",
    "    \"\"\"\n",
    "    Load the training data.\n",
    "\n",
    "    Args:\n",
    "        dataset (str): Name of the dataset to load.\n",
    "        seed (int): Seed for the random number generator.\n",
    "\n",
    "    Returns:\n",
    "        X_train (jax.numpy.ndarray): Input features for training.\n",
    "        Y_train (jax.numpy.ndarray): Target values for training.\n",
    "    \"\"\"\n",
    "    regr_dataset = pml.data.dataset.DatasetTabular(\n",
    "        data_path=f'../../data/{dataset}',\n",
    "        target_indices=[],\n",
    "        split_spec={'train': 0.8 - val_size, 'val': val_size, 'test': 0.2},\n",
    "        seed=seed,\n",
    "        standardize=True,\n",
    "    )\n",
    "    X_train, Y_train = regr_dataset.get_data(split='train', data_type='jax')\n",
    "    X_val, Y_val = regr_dataset.get_data(split='val', data_type='jax')\n",
    "\n",
    "    return X_train, Y_train, X_val, Y_val\n",
    "\n",
    "\n",
    "def exp_tuple_to_dict(exp: tuple) -> dict:\n",
    "    \"\"\"Convert an experiment tuple to a dictionary.\"\"\"\n",
    "    return {\n",
    "        'data': exp[0],\n",
    "        'activation': exp[1],\n",
    "        'hidden_structure': exp[2],\n",
    "        'replications': exp[3],\n",
    "    }\n",
    "\n",
    "\n",
    "def experiment_generator(config: dict) -> dict:\n",
    "    \"\"\"Generate the experiments (Cartesian Product).\"\"\"\n",
    "    exp_dimensions = []\n",
    "    for key, value in config.items():\n",
    "        if isinstance(value, list):\n",
    "            exp_dimensions.append(value)\n",
    "        elif isinstance(value, dict):\n",
    "            exp_dimensions.append(list(value.keys()))\n",
    "        else:\n",
    "            exp_dimensions.append([value])\n",
    "\n",
    "    exp_tuples = list(itertools.product(*exp_dimensions))\n",
    "    experiments = {\n",
    "        f'exp{str(i)}|' + '|'.join([str(e) for e in p]): p\n",
    "        for i, p in enumerate(exp_tuples)\n",
    "    }\n",
    "    return experiments\n",
    "\n",
    "\n",
    "def init_weights(layer: nn.Module) -> None:\n",
    "    \"\"\"Create checkpoint with network(s) to be loaded in learning.\"\"\"\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        nn.init.xavier_uniform_(layer.weight)\n",
    "        nn.init.zeros_(layer.bias)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-01T18:59:24.585419573Z",
     "start_time": "2024-02-01T18:59:24.541980520Z"
    }
   },
   "id": "41cc5d8c31fce88a"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    \"\"\"Simple MLP network.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size: int,\n",
    "        hidden_sizes: List[int],\n",
    "        activation: nn.modules.activation,\n",
    "        dropout_ratio: float,\n",
    "    ) -> None:\n",
    "        \"\"\"Instantiate MLP.\"\"\"\n",
    "        super().__init__()\n",
    "        hidden_id = '_'.join([str(x) for x in hidden_sizes])\n",
    "        self.model_id = f'MLP_{input_size}_{hidden_id}_2'\n",
    "        self.input_size = input_size\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        self.net = torch.nn.Sequential(torch.nn.Linear(input_size, hidden_sizes[0]))\n",
    "        for i, o in zip(hidden_sizes, hidden_sizes[1:] + [2]):\n",
    "            self.net.append(activation())\n",
    "            self.net.append(torch.nn.Linear(i, o))\n",
    "        self.dropout = nn.Dropout(dropout_ratio)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Define forward pass.\"\"\"\n",
    "        x = self.net(x)\n",
    "        return self.dropout(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-01T18:59:25.514982264Z",
     "start_time": "2024-02-01T18:59:25.478490975Z"
    }
   },
   "id": "da071d4ea07846f8"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "class NNLearner(pl.LightningModule):\n",
    "    \"\"\"Vanilla network training.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        x_train: torch.Tensor,\n",
    "        y_train: torch.Tensor,\n",
    "        x_val: torch.Tensor,\n",
    "        y_val: torch.Tensor,\n",
    "        model: nn.Module,\n",
    "        training_specs: Dict,\n",
    "        seed: int,\n",
    "    ) -> None:\n",
    "        \"\"\"Set up learner object.\"\"\"\n",
    "        super().__init__()\n",
    "        self.seed = seed\n",
    "        self.model = model\n",
    "        self.data_train = TensorDataset(x_train, y_train)\n",
    "        self.data_val = TensorDataset(x_val, y_val)\n",
    "\n",
    "        self.optimizer = optim.Adam(\n",
    "            params=self.model.parameters(), weight_decay=training_specs['weight_decay']\n",
    "        )\n",
    "        self.scheduler = None\n",
    "        self.training_specs = training_specs\n",
    "\n",
    "    def on_fit_start(self) -> None:\n",
    "        \"\"\"Set global seed.\"\"\"\n",
    "        pl.seed_everything(seed=self.seed)\n",
    "\n",
    "    def train_dataloader(self) -> DataLoader:\n",
    "        \"\"\"Set up data loader for training.\"\"\"\n",
    "        return DataLoader(\n",
    "            self.data_train,\n",
    "            batch_size=self.training_specs.get('batch_size'),\n",
    "            shuffle=True,\n",
    "            num_workers=1,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self) -> Union[DataLoader, None]:\n",
    "        \"\"\"Set up data loader for validation.\"\"\"\n",
    "        if len(self.data_val.tensors[0]) == 0:\n",
    "            return self.train_dataloader()\n",
    "        else:\n",
    "            return DataLoader(\n",
    "                self.data_val,\n",
    "                batch_size=self.data_val.tensors[0].shape[0],\n",
    "                num_workers=1,\n",
    "            )\n",
    "\n",
    "    def configure_optimizers(self) -> Dict:\n",
    "        \"\"\"Set up optimization-related objects.\"\"\"\n",
    "        return {'optimizer': self.optimizer}\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Define standard forward pass.\"\"\"\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch: Dict, batch_idx: int) -> torch.Tensor:\n",
    "        \"\"\"Define training routine.\"\"\"\n",
    "        x, y = batch\n",
    "        outputs = self.model(x)\n",
    "        mean_pred = outputs[:, 0]\n",
    "        std_pred = torch.exp(outputs[:, 1])\n",
    "        loss = torch.nn.functional.gaussian_nll_loss(mean_pred, y.squeeze(), std_pred)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch: Dict, batch_idx: int) -> None:\n",
    "        \"\"\"Define validation routine.\"\"\"\n",
    "        if len(self.data_val.tensors[1]) > 0:\n",
    "            x, y = batch\n",
    "            outputs = self.model(x)\n",
    "            mean_pred = outputs[:, 0]\n",
    "            std_pred = torch.exp(outputs[:, 1])\n",
    "            loss_val = torch.nn.functional.gaussian_nll_loss(\n",
    "                mean_pred, y.squeeze(), std_pred\n",
    "            )\n",
    "            self.log('loss_val', loss_val)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-01T18:59:26.311993200Z",
     "start_time": "2024-02-01T18:59:26.259482007Z"
    }
   },
   "id": "994d8e6bcf3dc7b5"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "class SGDEnsemble:\n",
    "    \"\"\"Ensemble of SGD trained models.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, base_learner: nn.Module, ensemble_size: int, ckpt: str = ''\n",
    "    ) -> None:\n",
    "        \"\"\"Instantiate ensemble.\"\"\"\n",
    "        self.ensemble_size = ensemble_size\n",
    "        self.base_learner = base_learner\n",
    "        self.ckpt = ckpt\n",
    "        self.weights = []\n",
    "\n",
    "    def train(\n",
    "        self,\n",
    "        x: torch.tensor,\n",
    "        y: torch.tensor,\n",
    "        x_val: torch.tensor,\n",
    "        y_val: torch.tensor,\n",
    "        log_at_epoch: list,\n",
    "        training_specs: dict,\n",
    "    ) -> None:\n",
    "        \"\"\"Train the ensemble.\"\"\"\n",
    "        if len(self.ckpt) == 0 and len(log_at_epoch) > 0:\n",
    "            raise ValueError('Logging requires path to checkpoint')\n",
    "\n",
    "        for idx in range(self.ensemble_size):\n",
    "            bl = copy.deepcopy(self.base_learner)\n",
    "            bl.apply(init_weights)\n",
    "            nn_learner = NNLearner(\n",
    "                x_train=x,\n",
    "                y_train=y,\n",
    "                x_val=x_val,\n",
    "                y_val=y_val,\n",
    "                model=bl,\n",
    "                training_specs=training_specs,\n",
    "                seed=idx,\n",
    "            )\n",
    "            if len(y_val) > 0:\n",
    "                callback = [EarlyStopping('loss_val', patience=30, check_finite=False)]\n",
    "            else:\n",
    "                callback = []\n",
    "            trainer = pl.Trainer(\n",
    "                max_epochs=training_specs['max_epochs'],\n",
    "                num_sanity_val_steps=0,\n",
    "                deterministic=True,\n",
    "                callbacks=callback,\n",
    "            )\n",
    "            print(f'---> Training ensemble member {idx + 1}...')\n",
    "            trainer.fit(nn_learner)\n",
    "\n",
    "            stdict = nn_learner.model.state_dict()\n",
    "            weight_keys_in = list(stdict.keys())\n",
    "            weight_keys_out = []\n",
    "            for i in range(len(weight_keys_in) // 2):\n",
    "                weight_keys_out.append(f'W{i + 1}')\n",
    "                weight_keys_out.append(f'b{i + 1}')\n",
    "            final_weights = {}\n",
    "            for i, o in zip(weight_keys_in, weight_keys_out):\n",
    "                final_weights[o] = bl.state_dict()[i].data.numpy()\n",
    "            np.savez(os.path.join(self.ckpt, f'{idx}.npz'), **final_weights)\n",
    "            torch.save(stdict, os.path.join(self.ckpt, f'stdict_{idx}.pt'))\n",
    "\n",
    "    def predict(self, x: torch.tensor):\n",
    "        \"\"\"Predict with the ensemble.\"\"\"\n",
    "        ensemble_prediction = []\n",
    "        for idx in range(self.ensemble_size):\n",
    "            bl = self.base_learner\n",
    "            bl.load_state_dict(self.weights[idx])\n",
    "            prediction = bl(x)\n",
    "            ensemble_prediction.append(prediction)\n",
    "        return torch.stack(tuple(ensemble_prediction))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-01T18:59:27.073298694Z",
     "start_time": "2024-02-01T18:59:27.035245880Z"
    }
   },
   "id": "57c327c21acc529b"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def run_experiment(\n",
    "    exp: tuple, path: str, training_specs: dict, val_size: float\n",
    ") -> None:\n",
    "    \"\"\"Run a single experiment.\"\"\"\n",
    "    start_time = time.time()\n",
    "    # load the data\n",
    "    X_train, Y_train, X_val, Y_val = load_data(exp[0], seed=exp[3], val_size=val_size)\n",
    "    exp_dict = exp_tuple_to_dict(exp)\n",
    "    if training_specs['batch_size'] == -1:\n",
    "        training_specs['batch_size'] = X_train.shape[0]\n",
    "\n",
    "    if exp_dict['activation'] == 'relu':\n",
    "        activation = nn.ReLU\n",
    "    elif exp_dict['activation'] == 'tanh':\n",
    "        activation = nn.Tanh\n",
    "    else:\n",
    "        raise ValueError(f'Activation {exp_dict[\"activation\"]} not supported.')\n",
    "\n",
    "    # initialize the model\n",
    "    base_learner = MLP(\n",
    "        input_size=X_train.shape[1],\n",
    "        hidden_sizes=[int(d) for d in exp_dict['hidden_structure'].split('-')],\n",
    "        activation=activation,\n",
    "        dropout_ratio=0.0,\n",
    "    )\n",
    "    deep_ensemble = SGDEnsemble(\n",
    "        base_learner=base_learner,\n",
    "        ensemble_size=ENSEMBLE_SIZE,\n",
    "        ckpt=path,\n",
    "    )\n",
    "    deep_ensemble.train(\n",
    "        x=torch.from_numpy(np.array(X_train)),\n",
    "        y=torch.from_numpy(np.array(Y_train)),\n",
    "        x_val=torch.from_numpy(np.array(X_val)),\n",
    "        y_val=torch.from_numpy(np.array(Y_val)),\n",
    "        log_at_epoch=[],\n",
    "        training_specs=training_specs,\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f'{(time.time() - start_time) / 60:.2f} min '\n",
    "        f'for {training_specs[\"exp_identifier\"]}'\n",
    "    )\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-01T18:59:27.831083229Z",
     "start_time": "2024-02-01T18:59:27.799388836Z"
    }
   },
   "id": "d329a300a110e1da"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/lisa/Documents/0_work/repos_research/bnn_connecting_the_dots/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:67: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "Missing logger folder: /home/lisa/Documents/0_work/repos_research/bnn_connecting_the_dots/experiments/fcn_ensembles/lightning_logs\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | MLP  | 466   \n",
      "-------------------------------\n",
      "466       Trainable params\n",
      "0         Non-trainable params\n",
      "466       Total params\n",
      "0.002     Total estimated model params size (MB)\n",
      "Seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Training ensemble member 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lisa/Documents/0_work/repos_research/bnn_connecting_the_dots/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/home/lisa/Documents/0_work/repos_research/bnn_connecting_the_dots/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:492: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "/home/lisa/Documents/0_work/repos_research/bnn_connecting_the_dots/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ad5de88a6bc6445d852d7b3d10e4d405"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lisa/Documents/0_work/repos_research/bnn_connecting_the_dots/.venv/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | MLP  | 466   \n",
      "-------------------------------\n",
      "466       Trainable params\n",
      "0         Non-trainable params\n",
      "466       Total params\n",
      "0.002     Total estimated model params size (MB)\n",
      "Seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Training ensemble member 2...\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "73bd7976cf03460cb8702f057ab6700a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | MLP  | 466   \n",
      "-------------------------------\n",
      "466       Trainable params\n",
      "0         Non-trainable params\n",
      "466       Total params\n",
      "0.002     Total estimated model params size (MB)\n",
      "Seed set to 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Training ensemble member 3...\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2c24602d6ed248248a87ce0ae084add1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | MLP  | 466   \n",
      "-------------------------------\n",
      "466       Trainable params\n",
      "0         Non-trainable params\n",
      "466       Total params\n",
      "0.002     Total estimated model params size (MB)\n",
      "Seed set to 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Training ensemble member 4...\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2dadbe69d2574bd1a7a7898f0c47f77a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | MLP  | 466   \n",
      "-------------------------------\n",
      "466       Trainable params\n",
      "0         Non-trainable params\n",
      "466       Total params\n",
      "0.002     Total estimated model params size (MB)\n",
      "Seed set to 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Training ensemble member 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _releaseLock at 0x7fe19a91b760>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/logging/__init__.py\", line 228, in _releaseLock\n",
      "    def _releaseLock():\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b238e06cfaee4b6281fb0a2e17699378"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | MLP  | 466   \n",
      "-------------------------------\n",
      "466       Trainable params\n",
      "0         Non-trainable params\n",
      "466       Total params\n",
      "0.002     Total estimated model params size (MB)\n",
      "Seed set to 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Training ensemble member 6...\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a3cbfa368f9a45cba3558acfd0be672d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9998efc341d7469b8b40269f82923dd1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "905fc705c4ba47af873fe76c68f6d4d9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ae727040407d49a6a5c533857eb025df"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | MLP  | 466   \n",
      "-------------------------------\n",
      "466       Trainable params\n",
      "0         Non-trainable params\n",
      "466       Total params\n",
      "0.002     Total estimated model params size (MB)\n",
      "Seed set to 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Training ensemble member 7...\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "28ef9b88f1674786906baed332ddc016"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | MLP  | 466   \n",
      "-------------------------------\n",
      "466       Trainable params\n",
      "0         Non-trainable params\n",
      "466       Total params\n",
      "0.002     Total estimated model params size (MB)\n",
      "Seed set to 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Training ensemble member 8...\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ec905ad0177d4082b3c2550c0a1c634f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | MLP  | 466   \n",
      "-------------------------------\n",
      "466       Trainable params\n",
      "0         Non-trainable params\n",
      "466       Total params\n",
      "0.002     Total estimated model params size (MB)\n",
      "Seed set to 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Training ensemble member 9...\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ceb8adf502cf4d8b889c84c6e23a8d5d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | MLP  | 466   \n",
      "-------------------------------\n",
      "466       Trainable params\n",
      "0         Non-trainable params\n",
      "466       Total params\n",
      "0.002     Total estimated model params size (MB)\n",
      "Seed set to 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Training ensemble member 10...\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "252bc88fd1df4410991ae334dfae3523"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | MLP  | 466   \n",
      "-------------------------------\n",
      "466       Trainable params\n",
      "0         Non-trainable params\n",
      "466       Total params\n",
      "0.002     Total estimated model params size (MB)\n",
      "Seed set to 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Training ensemble member 11...\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aa1da521d1f54a7ba0a07fbb0ff87145"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name  | Type | Params\n",
      "-------------------------------\n",
      "0 | model | MLP  | 466   \n",
      "-------------------------------\n",
      "466       Trainable params\n",
      "0         Non-trainable params\n",
      "466       Total params\n",
      "0.002     Total estimated model params size (MB)\n",
      "Seed set to 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Training ensemble member 12...\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6b4cae9743d24f0dbca973f5e0864311"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5b99be0505024276a6857f9b240bf02d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "919af3b3beeb40a39c0a1d3aa7842a82"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "402a853e618d4f51af48269abc2ef97d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2f8b2d7e549146829ad9561ded57e59f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "82b1b602b9c945338fda3e42db951a08"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "330392b3ee62409abf7c5c80ccddadcb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1d54de229c384305841b0d2f05f638e4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c7cee2a92d92490a861b8d838fe38570"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "61910d8f751d40058ab0a6c8de54d656"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9cb335afd4374cfb8e3012bb19bd1f3a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4a9366f7501d412b9801f377cc63ffe3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4a677d4974434b2ca67c5061f06ccc26"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f9b685647a3140eaa765686cc57fa128"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bf517fc1e11d4251824504c5e0944047"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2a5a2003ba9741f1ac59ef5707824c7f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c50740706f4f4706824f638ae59d3ab0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "76a5a98521054f4f9d6718b907431d80"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "29e38be0715442b7ab97cf965024bcf4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "52f885df5a05488da60ffa29f0a115d5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fe524b08b1b249259a59d77d16eee56d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f0196331e2be4336bf51e4f9fa85231d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e9be88903fac4f809488acb6063c3b39"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "80bb1bd1d44344b39740eee5d6f96940"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "main_path = '../../results/de/'\n",
    "os.makedirs(main_path, exist_ok=True)\n",
    "config = load_config('../../experiments/fcn_ensembles/config.yaml')\n",
    "experiments = experiment_generator(config)\n",
    "training_configs = itertools.product(WEIGHT_DECAY, BATCH_SIZE, VAL_SIZE)\n",
    "\n",
    "# Run the experiments\n",
    "for exp_name, exp in experiments.items():\n",
    "    for wd, bs, vs in training_configs:\n",
    "        expd = exp_tuple_to_dict(exp)\n",
    "        isval = 'val' if vs > 0 else 'noval'\n",
    "        exp_identifier = (\n",
    "            f'{expd[\"data\"]}|{expd[\"hidden_structure\"]}|{expd[\"activation\"]}|'\n",
    "            + f'wd{str(wd)}|bs{str(bs)}|{isval}|{expd[\"replications\"]}|'\n",
    "        )\n",
    "        training_specs = {\n",
    "            'max_epochs': MAX_EPOCHS,\n",
    "            'weight_decay': wd,\n",
    "            'batch_size': bs,\n",
    "            'exp_identifier': exp_identifier,\n",
    "        }\n",
    "        dir_name = os.path.join(main_path, exp_identifier)\n",
    "        os.makedirs(dir_name, exist_ok=True)\n",
    "        run_experiment(exp, dir_name, training_specs, vs)\n",
    "\n",
    "    print('All experiments have been run.')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-02-01T18:59:28.700084940Z"
    }
   },
   "id": "f6f7dca2d6d09903"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
