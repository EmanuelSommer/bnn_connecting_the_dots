{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af7f9ceb68c9785",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-24T08:53:05.603647714Z",
     "start_time": "2024-01-24T08:53:02.937438138Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from experiments.fcn_bnns.utils.analysis_utils import *\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, List\n",
    "import probabilisticml as pml\n",
    "# if already loaded unload and reload probabilisticml\n",
    "import importlib, sys\n",
    "if 'probabilisticml' in sys.modules:\n",
    "    importlib.reload(pml)\n",
    "else:\n",
    "    import probabilisticml as pml\n",
    "    \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dec86cfeffc6f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-24T09:01:57.976877560Z",
     "start_time": "2024-01-24T09:01:57.792165450Z"
    }
   },
   "outputs": [],
   "source": [
    "exp_info = {\n",
    "    \"data\": \"airfoil.data\",\n",
    "    \"replications\": 1,\n",
    "}\n",
    "X_train, Y_train = load_data(exp_info, splittype='train', data_path=\"../data/\")\n",
    "X_val, Y_val = load_data(exp_info, splittype='val', data_path=\"../data/\")\n",
    "X_train = torch.from_numpy(np.array(X_train))\n",
    "y_train = torch.from_numpy(np.array(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce80144b8dffebe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-24T09:04:10.217014392Z",
     "start_time": "2024-01-24T09:04:10.176195672Z"
    }
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    \"\"\"Simple MLP network.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self, \n",
    "            input_size: int, \n",
    "            hidden_sizes: List[int], \n",
    "            activation: torch.nn.modules.activation,\n",
    "            dropout_ratio: float\n",
    "    ) -> None:\n",
    "        \"\"\"Instantiate MLP.\"\"\"\n",
    "        super().__init__()\n",
    "        hidden_id = '_'.join([str(x) for x in hidden_sizes])\n",
    "        self.model_id = f'MLP_{input_size}_{hidden_id}_2'\n",
    "        self.input_size = input_size\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        self.net = torch.nn.Sequential(torch.nn.Linear(input_size, hidden_sizes[0]))\n",
    "        for i, o in zip(hidden_sizes, hidden_sizes[1:] + [2]):\n",
    "            self.net.append(activation())\n",
    "            self.net.append(torch.nn.Linear(i, o))\n",
    "        self.dropout = nn.Dropout(dropout_ratio)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Define forward pass.\"\"\"\n",
    "        x = self.net(x)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65719c9b130329df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-24T09:05:38.389200087Z",
     "start_time": "2024-01-24T09:05:38.341346495Z"
    }
   },
   "outputs": [],
   "source": [
    "foo = MLP(input_size=X_train.shape[1], hidden_sizes=[16, 16], activation=torch.nn.ReLU, dropout_ratio=0.)\n",
    "list(foo.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48aa9eb961fb533b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-23T17:12:17.184618910Z",
     "start_time": "2024-01-23T17:12:17.130346436Z"
    }
   },
   "outputs": [],
   "source": [
    "class SingleHiddenRELUModel(nn.Module):\n",
    "    def __init__(self, input_size: int = 1, hidden_size: int = 16):\n",
    "        super(SingleHiddenRELUModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features=input_size, out_features=hidden_size)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(in_features=hidden_size, out_features=hidden_size)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(in_features=hidden_size, out_features=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu1(self.fc1(x))\n",
    "        x = self.relu2(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        # the one dimension is the output the other the log var of a gaussian\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebeeaaf088516d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-23T17:53:47.942450880Z",
     "start_time": "2024-01-23T17:53:47.890118951Z"
    }
   },
   "outputs": [],
   "source": [
    "def init_weights(layer: nn.Module) -> None:\n",
    "    \"\"\"Create checkpoint with network(s) to be loaded in learning.\"\"\"\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        nn.init.xavier_uniform_(layer.weight)\n",
    "        nn.init.zeros_(layer.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b505ea5d1354ce90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-23T17:53:48.897079898Z",
     "start_time": "2024-01-23T17:53:48.842830949Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_as_json(dictionary: Dict, target: str) -> None:\n",
    "    \"\"\"Save a python object as JSON file.\"\"\"\n",
    "    with open(target, 'w', encoding='utf-8') as f:\n",
    "        json.dump(dictionary, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5dd5480a731f1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-23T18:01:27.766809340Z",
     "start_time": "2024-01-23T18:01:27.700674853Z"
    }
   },
   "outputs": [],
   "source": [
    "class SGDEnsemble:\n",
    "    def __init__(self, base_learner: nn.Module, ensemble_size: int, ckpt: str='') -> None:\n",
    "        \"\"\"Instantiate ensemble.\"\"\"\n",
    "        self.ensemble_size = ensemble_size\n",
    "        self.base_learner = base_learner\n",
    "        self.ckpt = ckpt\n",
    "        self.weights = []\n",
    "            \n",
    "    def train(\n",
    "            self,\n",
    "            num_epochs: int, \n",
    "            x: torch.tensor,\n",
    "            y: torch.tensor,\n",
    "            criterion: torch.nn.modules.loss,\n",
    "            log_at_epoch: list,\n",
    "    ):\n",
    "        if len(self.ckpt) == 0 and len(log_at_epoch) > 0:\n",
    "            raise ValueError('Loggin requires path to checkpoint')\n",
    "        \n",
    "        for idx in range(self.ensemble_size):\n",
    "            bl = deepcopy(self.base_learner)\n",
    "            torch.manual_seed(idx)\n",
    "            random.seed(idx)\n",
    "            bl.apply(init_weights)\n",
    "            opt = optim.Adam(bl.parameters(), lr=0.01, weight_decay=0.01)\n",
    "            with tqdm(total=num_epochs, desc=\"Training Progress\") as pbar:\n",
    "                for epoch in range(num_epochs):\n",
    "                    # Forward pass\n",
    "                    outputs = bl(x)\n",
    "                    mean_pred = outputs[:, 0]\n",
    "                    std_pred = torch.exp(outputs[:, 1])\n",
    "                    loss = criterion(mean_pred, y.squeeze(), std_pred)\n",
    "                    \n",
    "                    if torch.isnan(loss).any() or torch.isinf(loss).any() or loss.item() < -1e6:\n",
    "                        print(\"Loss exploded, breaking\")\n",
    "                        break\n",
    "                    # Backward pass and optimization\n",
    "                    opt.zero_grad()\n",
    "                    loss.backward()\n",
    "                    opt.step()\n",
    "                    pbar.update(1)\n",
    "                    pbar.set_postfix_str(\"Loss: {:.4f}\".format(loss.item()))\n",
    "                    \n",
    "                    # Weights\n",
    "                    current_weights = bl.state_dict()\n",
    "                    if len(log_at_epoch) > 0 and epoch in log_at_epoch:\n",
    "                        torch.save(current_weights, self.ckpt + f'weights_member_{idx}_epoch_{epoch}.pt')\n",
    "                        # save_as_json(current_weights, self.ckpt + f'weights_member_{idx}_epoch_{epoch}.json')\n",
    "            self.weights.append(current_weights)\n",
    "            \n",
    "    def predict(self, x: torch.tensor):\n",
    "        ensemble_prediction = []\n",
    "        for idx in range(self.ensemble_size):\n",
    "            bl = self.base_learner\n",
    "            bl.load_state_dict(self.weights[idx])\n",
    "            prediction = bl(x)\n",
    "            ensemble_prediction.append(prediction)\n",
    "        return torch.stack(tuple(ensemble_prediction))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbaadbe429c531d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-23T18:01:29.583945982Z",
     "start_time": "2024-01-23T18:01:29.526094613Z"
    }
   },
   "outputs": [],
   "source": [
    "nsync = SGDEnsemble(\n",
    "    base_learner=MLP(input_size=X_train.shape[1], hidden_sizes=[(16, 16), (16, 16)], activation=torch.nn.ReLU, dropout_ratio=0.), \n",
    "    ensemble_size=1,\n",
    "    ckpt='/home/user/Downloads/'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913adfbd647e52d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-23T18:01:36.433598658Z",
     "start_time": "2024-01-23T18:01:30.300434189Z"
    }
   },
   "outputs": [],
   "source": [
    "nsync.train(\n",
    "    num_epochs=1000,\n",
    "    x=X_train,\n",
    "    y=y_train,\n",
    "    criterion=nn.GaussianNLLLoss(),\n",
    "    log_at_epoch=[999]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f14840dd2816e6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-23T17:56:22.238451849Z",
     "start_time": "2024-01-23T17:56:22.173257138Z"
    }
   },
   "outputs": [],
   "source": [
    "# predict on the validation set\n",
    "X_val = torch.from_numpy(np.array(X_val))\n",
    "y_val = torch.from_numpy(np.array(Y_val))\n",
    "outputs_val = nsync.predict(X_val).mean(0)\n",
    "mean_pred = outputs_val[:, 0]\n",
    "# print(mean_pred[:10])\n",
    "# print(outputs[:10, 1])\n",
    "# print(y_val[:10])\n",
    "rmse = torch.sqrt(torch.mean((y_val.squeeze() - mean_pred)**2))\n",
    "print(\"RMSE: {:.4f}\".format(rmse.item()))\n",
    "# rmse of constant 0 predictor\n",
    "rmse_0 = torch.sqrt(torch.mean(y_val**2))\n",
    "print(\"RMSE_0: {:.4f}\".format(rmse_0.item()))\n",
    "# train a linear regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression().fit(X_train, Y_train)\n",
    "print(\"RMSE_lin: {:.4f}\".format(np.sqrt(np.mean((np.array(y_val) - reg.predict(X_val))**2))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
